{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8720f84c3675461795d87db7c65fdd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_685b97514d28481096e5f30f85db7cd2",
              "IPY_MODEL_fe997e3900684b979f697272887e39ad",
              "IPY_MODEL_942b56d289024ce7ab9b0b26dfdd9bcd"
            ],
            "layout": "IPY_MODEL_0deba28625e14f34a19e20163300d423"
          }
        },
        "685b97514d28481096e5f30f85db7cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ebf794079d43558fb67641de18a5e8",
            "placeholder": "​",
            "style": "IPY_MODEL_b34a5810d1444b3e90eea36991f82fa3",
            "value": "Batches: 100%"
          }
        },
        "fe997e3900684b979f697272887e39ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0709aff9f49b4f9c91dc9de0c3e3acf2",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f3bd6c9c0c242a3a4c83f42abc27cfb",
            "value": 3125
          }
        },
        "942b56d289024ce7ab9b0b26dfdd9bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b53c26422a4d8ea4db27f425a4b732",
            "placeholder": "​",
            "style": "IPY_MODEL_437767fe2b0548d39dc82d4c62ae5f7c",
            "value": " 3125/3125 [02:21&lt;00:00, 70.98it/s]"
          }
        },
        "0deba28625e14f34a19e20163300d423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ebf794079d43558fb67641de18a5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34a5810d1444b3e90eea36991f82fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0709aff9f49b4f9c91dc9de0c3e3acf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3bd6c9c0c242a3a4c83f42abc27cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b53c26422a4d8ea4db27f425a4b732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437767fe2b0548d39dc82d4c62ae5f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGcCpBWs2iXO",
        "outputId": "5ba7250d-e2ac-4449-dcdd-954e67217721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bertopic[all] sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaFHQ8CF2lLZ",
        "outputId": "11a17866-fa4b-43e4-ba86-3c536e0a6481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: bertopic 0.17.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "# from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ],
      "metadata": {
        "id": "6S70NVWI5RGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/review_sample.csv\")\n",
        "df = df[['text', 'stars']].dropna()\n",
        "df['sentiment_label'] = df['stars'].apply(lambda x: 'positive' if x >= 4 else ('negative' if x <= 2 else 'neutral'))\n",
        "\n"
      ],
      "metadata": {
        "id": "2WHaeEpP6X0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for topic modeling\n",
        "sampled_df = df.sample(100000, random_state=42)\n",
        "docs = sampled_df['text'].tolist()"
      ],
      "metadata": {
        "id": "c_R292Em7bSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sentence transformer for LLM-based embeddings\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize BERTopic with custom embedding model\n",
        "topic_model = BERTopic(embedding_model=embedding_model, verbose=True)\n",
        "\n",
        "# Fit and transform\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "# Add topics back to dataframe\n",
        "sampled_df[\"topic\"] = topics\n",
        "\n",
        "# Show top topics\n",
        "topic_info = topic_model.get_topic_info()\n",
        "print(topic_info.head())\n",
        "\n",
        "# Show example documents from a few topics\n",
        "for topic_id in topic_info['Topic'].head(5):\n",
        "    print(f\"\\nTopic {topic_id}:\")\n",
        "    print(topic_model.get_topic(topic_id))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815,
          "referenced_widgets": [
            "8720f84c3675461795d87db7c65fdd55",
            "685b97514d28481096e5f30f85db7cd2",
            "fe997e3900684b979f697272887e39ad",
            "942b56d289024ce7ab9b0b26dfdd9bcd",
            "0deba28625e14f34a19e20163300d423",
            "03ebf794079d43558fb67641de18a5e8",
            "b34a5810d1444b3e90eea36991f82fa3",
            "0709aff9f49b4f9c91dc9de0c3e3acf2",
            "9f3bd6c9c0c242a3a4c83f42abc27cfb",
            "67b53c26422a4d8ea4db27f425a4b732",
            "437767fe2b0548d39dc82d4c62ae5f7c"
          ]
        },
        "id": "95UwpsVv5SZY",
        "outputId": "13e67534-ee45-4b1c-bec3-d4d772ba3c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-30 02:42:27,754 - BERTopic - Embedding - Transforming documents to embeddings.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8720f84c3675461795d87db7c65fdd55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-30 02:44:52,661 - BERTopic - Embedding - Completed ✓\n",
            "2025-03-30 02:44:52,664 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2025-03-30 02:47:28,724 - BERTopic - Dimensionality - Completed ✓\n",
            "2025-03-30 02:47:28,728 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2025-03-30 02:47:42,148 - BERTopic - Cluster - Completed ✓\n",
            "2025-03-30 02:47:42,176 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
            "2025-03-30 02:47:49,886 - BERTopic - Representation - Completed ✓\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Topic  Count                             Name  \\\n",
            "0     -1  42735               -1_was_food_we_the   \n",
            "1      0   2632  0_food_great_service_atmosphere   \n",
            "2      1   2270          1_sushi_roll_rolls_tuna   \n",
            "3      2   2161    2_pizza_crust_pizzas_delivery   \n",
            "4      3   1967          3_hotel_room_stay_rooms   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [was, food, we, the, were, it, and, had, with,...   \n",
            "1  [food, great, service, atmosphere, friendly, s...   \n",
            "2  [sushi, roll, rolls, tuna, hibachi, sashimi, j...   \n",
            "3  [pizza, crust, pizzas, delivery, pepperoni, to...   \n",
            "4  [hotel, room, stay, rooms, desk, bed, stayed, ...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [Hate to do this to Villagio but I feel it nec...  \n",
            "1  [I love this place!!! They have great service,...  \n",
            "2  [I have tried this place 3 times now over the ...  \n",
            "3  [We ordered from here for the first time a few...  \n",
            "4  [Giving 5 stars for this hotel in this price r...  \n",
            "\n",
            "Topic -1:\n",
            "[('was', np.float64(0.001789411301524333)), ('food', np.float64(0.0017127276829890016)), ('we', np.float64(0.0017108740630665065)), ('the', np.float64(0.001706157213450792)), ('were', np.float64(0.0016958255894273934)), ('it', np.float64(0.0016643645953966452)), ('and', np.float64(0.0016626407638915728)), ('had', np.float64(0.001618081987623161)), ('with', np.float64(0.0016154529473275793)), ('of', np.float64(0.0016151113387475615))]\n",
            "\n",
            "Topic 0:\n",
            "[('food', np.float64(0.006284051008436829)), ('great', np.float64(0.004688947507802585)), ('service', np.float64(0.004499073626506893)), ('atmosphere', np.float64(0.0038294988750599956)), ('friendly', np.float64(0.0036937449359536346)), ('staff', np.float64(0.003580683311920522)), ('place', np.float64(0.003449382214334471)), ('amazing', np.float64(0.003439882410303013)), ('love', np.float64(0.003317315426528948)), ('excellent', np.float64(0.003315391674824272))]\n",
            "\n",
            "Topic 1:\n",
            "[('sushi', np.float64(0.028585098160515788)), ('roll', np.float64(0.01101780658318017)), ('rolls', np.float64(0.009774100643600713)), ('tuna', np.float64(0.005739566520797438)), ('hibachi', np.float64(0.005468637175295395)), ('sashimi', np.float64(0.004802080948772771)), ('japanese', np.float64(0.004656786619892664)), ('salmon', np.float64(0.0036695292722493567)), ('tempura', np.float64(0.003588085898777206)), ('fish', np.float64(0.0035337302855074195))]\n",
            "\n",
            "Topic 2:\n",
            "[('pizza', np.float64(0.028129570824751655)), ('crust', np.float64(0.008906198978797037)), ('pizzas', np.float64(0.007033025415810195)), ('delivery', np.float64(0.004756012558212941)), ('pepperoni', np.float64(0.004227400865455788)), ('toppings', np.float64(0.004202764222880316)), ('thin', np.float64(0.0038765273034726514)), ('slice', np.float64(0.00380618738974668)), ('cheese', np.float64(0.0030766494548140682)), ('oven', np.float64(0.003063278616000653))]\n",
            "\n",
            "Topic 3:\n",
            "[('hotel', np.float64(0.014271759253705973)), ('room', np.float64(0.011829824641612474)), ('stay', np.float64(0.00790802400774465)), ('rooms', np.float64(0.007758745187417774)), ('desk', np.float64(0.005825268635477253)), ('bed', np.float64(0.005661453438117096)), ('stayed', np.float64(0.0056115631951164325)), ('pool', np.float64(0.004309103129135829)), ('front', np.float64(0.0037295209153701825)), ('clean', np.float64(0.0035377825029610575))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for topic modeling\n",
        "sampled_df = df.sample(100000, random_state=42)\n",
        "docs = sampled_df['text'].tolist()"
      ],
      "metadata": {
        "id": "erolc8NAkaGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Get c-TF-IDF matrix (topic-word distributions)\n",
        "ctfidf = topic_model.c_tf_idf_\n",
        "\n",
        "# Calculate pairwise cosine similarity\n",
        "cos_sim = cosine_similarity(ctfidf)\n",
        "\n",
        "# Mask diagonal (self-similarity)\n",
        "np.fill_diagonal(cos_sim, 0)\n",
        "\n",
        "# Mean similarity across different topics\n",
        "mean_similarity = np.mean(cos_sim)\n",
        "\n",
        "# Invert to interpret as \"coherence\" (lower similarity = more distinct = better)\n",
        "coherence_score = 1 - mean_similarity\n",
        "\n",
        "print(\"Approximate Topic Coherence Score (inverted cosine sim):\", coherence_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeJ96lhfk2P8",
        "outputId": "6e9690ae-e355-4bca-d5b2-4c6288b75efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Topic Coherence Score (inverted cosine sim): 0.9135639298760588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize topic clusters in 2D space\n",
        "topic_model.visualize_documents(docs)\n",
        "\n",
        "# Visualize most frequent topics\n",
        "topic_model.visualize_barchart(top_n_topics=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "mpAGFKkN5jG-",
        "outputId": "77fb4832-8d89-4313-a730-86c8fd942494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b2edef2e-46cb-480f-8a91-72357a130bd7\" class=\"plotly-graph-div\" style=\"height:750px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2edef2e-46cb-480f-8a91-72357a130bd7\")) {                    Plotly.newPlot(                        \"b2edef2e-46cb-480f-8a91-72357a130bd7\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.0036937449359536346,0.0038294988750599956,0.004499073626506893,0.004688947507802585,0.006284051008436829],\"y\":[\"friendly  \",\"atmosphere  \",\"service  \",\"great  \",\"food  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.005468637175295395,0.005739566520797438,0.009774100643600713,0.01101780658318017,0.028585098160515788],\"y\":[\"hibachi  \",\"tuna  \",\"rolls  \",\"roll  \",\"sushi  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.004227400865455788,0.004756012558212941,0.007033025415810195,0.008906198978797037,0.028129570824751655],\"y\":[\"pepperoni  \",\"delivery  \",\"pizzas  \",\"crust  \",\"pizza  \"],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#E69F00\"},\"orientation\":\"h\",\"x\":[0.005825268635477253,0.007758745187417774,0.00790802400774465,0.011829824641612474,0.014271759253705973],\"y\":[\"desk  \",\"rooms  \",\"stay  \",\"room  \",\"hotel  \"],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#56B4E9\"},\"orientation\":\"h\",\"x\":[0.0037140966860436577,0.004213020965380679,0.011489223811957114,0.014345265431828996,0.022728147354931814],\"y\":[\"patty  \",\"bun  \",\"fries  \",\"burgers  \",\"burger  \"],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":\"#009E73\"},\"orientation\":\"h\",\"x\":[0.004957093875441948,0.005290014343192737,0.007791176847691931,0.00973440907389356,0.024605692570674888],\"y\":[\"shop  \",\"espresso  \",\"latte  \",\"starbucks  \",\"coffee  \"],\"type\":\"bar\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":\"#F0E442\"},\"orientation\":\"h\",\"x\":[0.012094789720288912,0.012502195873436083,0.013866131869001938,0.013960681120398917,0.030357916681526032],\"y\":[\"stylist  \",\"haircut  \",\"cut  \",\"salon  \",\"hair  \"],\"type\":\"bar\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.0035780206241504513,0.0037832203033492814,0.004086694099825327,0.010876130665063431,0.019035574859963714],\"y\":[\"meatballs  \",\"gnocchi  \",\"spaghetti  \",\"pasta  \",\"italian  \"],\"type\":\"bar\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.013003789636399981,0.014080311734275609,0.016403686272022214,0.02160704236786262,0.026659682045779103],\"y\":[\"salon  \",\"gel  \",\"pedicure  \",\"nail  \",\"nails  \"],\"type\":\"bar\",\"xaxis\":\"x9\",\"yaxis\":\"y9\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.004080777243455728,0.004247502405689587,0.004334647836182482,0.0047015861207652596,0.00494550562216082],\"y\":[\"she  \",\"our  \",\"minutes  \",\"us  \",\"table  \"],\"type\":\"bar\",\"xaxis\":\"x10\",\"yaxis\":\"y10\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.7555555555555555,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.7555555555555555,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.7555555555555555,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.7555555555555555,1.0],\"showgrid\":true},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.37777777777777777,0.6222222222222222],\"showgrid\":true},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.37777777777777777,0.6222222222222222],\"showgrid\":true},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.37777777777777777,0.6222222222222222],\"showgrid\":true},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.37777777777777777,0.6222222222222222],\"showgrid\":true},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,0.24444444444444446],\"showgrid\":true},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,0.24444444444444446],\"showgrid\":true},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.0,0.24444444444444446],\"showgrid\":true},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.0,0.24444444444444446],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 2\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 3\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 4\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6222222222222222,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 5\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6222222222222222,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 6\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6222222222222222,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 7\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6222222222222222,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 8\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.24444444444444446,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 9\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.24444444444444446,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1000,\"height\":750},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b2edef2e-46cb-480f-8a91-72357a130bd7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install -q transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBeq7TBl8Kmh",
        "outputId": "1db254d5-3495-4c26-a398-66d9cadfda0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# STEP 2: Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cleaned_reviews.csv\")\n",
        "df = df[['cleaned_text', 'stars']].dropna()\n",
        "\n",
        "# STEP 3: Create sentiment labels (set use_neutral=False for binary classification)\n",
        "use_neutral = True  # Set to False if you want only positive vs negative\n",
        "\n",
        "if use_neutral:\n",
        "    df['sentiment_label'] = df['stars'].apply(lambda x: 'positive' if x >= 4 else ('negative' if x <= 2 else 'neutral'))\n",
        "else:\n",
        "    df = df[df['stars'] != 3]  # Drop neutral reviews\n",
        "    df['sentiment_label'] = df['stars'].apply(lambda x: 'positive' if x >= 4 else 'negative')\n",
        "\n",
        "# Encode labels (optional)\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['sentiment_label'])\n"
      ],
      "metadata": {
        "id": "OYpDdW8H--Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downsample classes to handle imbalance\n",
        "df_majority = df[df.label == 2]  # positive\n",
        "df_minority = df[df.label != 2]\n",
        "\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(df_majority),\n",
        "                                 random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority, df_minority_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(df_balanced['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t99rdbEY--pg",
        "outputId": "2c51e1d2-f8fb-45ba-f59d-583e724d3bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "2    343321\n",
            "0    228202\n",
            "1    115119\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 0 if torch.cuda.is_available() else -1\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# STEP 5: Create classification pipeline with truncation enabled\n",
        "classifier = TextClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_all_scores=False\n",
        ")\n",
        "\n",
        "# STEP 6: Batch prediction\n",
        "batch_size = 64\n",
        "reviews = df['cleaned_text'].tolist()\n",
        "predictions = []\n",
        "total_batches = len(reviews) // batch_size + int(len(reviews) % batch_size != 0)\n",
        "\n",
        "for i in range(0, len(reviews), batch_size):\n",
        "    batch = reviews[i:i + batch_size]\n",
        "\n",
        "    # Tokenizer will handle truncation and padding correctly\n",
        "    results = classifier(batch)\n",
        "    predictions.extend([res['label'] for res in results])\n",
        "\n",
        "    if (i // batch_size) % 100 == 0:\n",
        "        print(f\"Processed {i // batch_size}/{total_batches} batches...\")\n",
        "\n",
        "# STEP 7: Map model labels to dataset labels\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"negative\",\n",
        "    # \"LABEL_1\": \"neutral\",   # If use_neutral = False, remove this\n",
        "    \"LABEL_2\": \"positive\"\n",
        "}\n",
        "df['predicted_sentiment'] = [label_map.get(label, 'neutral') for label in predictions]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olFA53Gw8H4-",
        "outputId": "488bac78-2e95-4edd-e539-3d9ca2efff2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0/6991 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100/6991 batches...\n",
            "Processed 200/6991 batches...\n",
            "Processed 300/6991 batches...\n",
            "Processed 400/6991 batches...\n",
            "Processed 500/6991 batches...\n",
            "Processed 600/6991 batches...\n",
            "Processed 700/6991 batches...\n",
            "Processed 800/6991 batches...\n",
            "Processed 900/6991 batches...\n",
            "Processed 1000/6991 batches...\n",
            "Processed 1100/6991 batches...\n",
            "Processed 1200/6991 batches...\n",
            "Processed 1300/6991 batches...\n",
            "Processed 1400/6991 batches...\n",
            "Processed 1500/6991 batches...\n",
            "Processed 1600/6991 batches...\n",
            "Processed 1700/6991 batches...\n",
            "Processed 1800/6991 batches...\n",
            "Processed 1900/6991 batches...\n",
            "Processed 2000/6991 batches...\n",
            "Processed 2100/6991 batches...\n",
            "Processed 2200/6991 batches...\n",
            "Processed 2300/6991 batches...\n",
            "Processed 2400/6991 batches...\n",
            "Processed 2500/6991 batches...\n",
            "Processed 2600/6991 batches...\n",
            "Processed 2700/6991 batches...\n",
            "Processed 2800/6991 batches...\n",
            "Processed 2900/6991 batches...\n",
            "Processed 3000/6991 batches...\n",
            "Processed 3100/6991 batches...\n",
            "Processed 3200/6991 batches...\n",
            "Processed 3300/6991 batches...\n",
            "Processed 3400/6991 batches...\n",
            "Processed 3500/6991 batches...\n",
            "Processed 3600/6991 batches...\n",
            "Processed 3700/6991 batches...\n",
            "Processed 3800/6991 batches...\n",
            "Processed 3900/6991 batches...\n",
            "Processed 4000/6991 batches...\n",
            "Processed 4100/6991 batches...\n",
            "Processed 4200/6991 batches...\n",
            "Processed 4300/6991 batches...\n",
            "Processed 4400/6991 batches...\n",
            "Processed 4500/6991 batches...\n",
            "Processed 4600/6991 batches...\n",
            "Processed 4700/6991 batches...\n",
            "Processed 4800/6991 batches...\n",
            "Processed 4900/6991 batches...\n",
            "Processed 5000/6991 batches...\n",
            "Processed 5100/6991 batches...\n",
            "Processed 5200/6991 batches...\n",
            "Processed 5300/6991 batches...\n",
            "Processed 5400/6991 batches...\n",
            "Processed 5500/6991 batches...\n",
            "Processed 5600/6991 batches...\n",
            "Processed 5700/6991 batches...\n",
            "Processed 5800/6991 batches...\n",
            "Processed 5900/6991 batches...\n",
            "Processed 6000/6991 batches...\n",
            "Processed 6100/6991 batches...\n",
            "Processed 6200/6991 batches...\n",
            "Processed 6300/6991 batches...\n",
            "Processed 6400/6991 batches...\n",
            "Processed 6500/6991 batches...\n",
            "Processed 6600/6991 batches...\n",
            "Processed 6700/6991 batches...\n",
            "Processed 6800/6991 batches...\n",
            "Processed 6900/6991 batches...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df[df['sentiment_label'].isin(['positive', 'negative'])]\n"
      ],
      "metadata": {
        "id": "wNuk2JNIhlNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Accuracy\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(df_clean['sentiment_label'], df_clean['predicted_sentiment'])\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(df_clean['sentiment_label'], df_clean['predicted_sentiment']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGnUcf9-JiOT",
        "outputId": "dc82d557-84cb-4cc7-e2f5-d203ce03bc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8366\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.96      0.49      0.65    104088\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.94      0.94      0.94    343321\n",
            "\n",
            "    accuracy                           0.84    447409\n",
            "   macro avg       0.63      0.48      0.53    447409\n",
            "weighted avg       0.94      0.84      0.87    447409\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df.sample(n=100000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# STEP 5: Load Karimbkh fine-tuned Yelp model\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "model_name = \"karimbkh/BERT_fineTuned_Sentiment_Classification_Yelp\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# STEP 6: Create classification pipeline with truncation\n",
        "classifier = TextClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_all_scores=False\n",
        ")\n",
        "\n",
        "# STEP 7: Perform batch inference\n",
        "batch_size = 64\n",
        "reviews = df_sample['cleaned_text'].tolist()\n",
        "predictions = []\n",
        "total_batches = len(reviews) // batch_size + int(len(reviews) % batch_size != 0)\n",
        "\n",
        "for i in range(0, len(reviews), batch_size):\n",
        "    batch = reviews[i:i + batch_size]\n",
        "    results = classifier(batch)\n",
        "    predictions.extend([res['label'] for res in results])\n",
        "\n",
        "    if (i // batch_size) % 50 == 0:\n",
        "        print(f\"Processed {i // batch_size}/{total_batches} batches...\")\n",
        "\n",
        "# STEP 8: Map model labels (LABEL_0, LABEL_1, LABEL_2) to sentiment\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"negative\",\n",
        "    # \"LABEL_1\": \"neutral\",\n",
        "    \"LABEL_2\": \"positive\"\n",
        "}\n",
        "df_sample['predicted_sentiment'] = [label_map.get(label, 'neutral') for label in predictions]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQtWdoRyjw7f",
        "outputId": "9c422c37-c9ee-48b3-f6e5-081283a05163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0/1563 batches...\n",
            "Processed 50/1563 batches...\n",
            "Processed 100/1563 batches...\n",
            "Processed 150/1563 batches...\n",
            "Processed 200/1563 batches...\n",
            "Processed 250/1563 batches...\n",
            "Processed 300/1563 batches...\n",
            "Processed 350/1563 batches...\n",
            "Processed 400/1563 batches...\n",
            "Processed 450/1563 batches...\n",
            "Processed 500/1563 batches...\n",
            "Processed 550/1563 batches...\n",
            "Processed 600/1563 batches...\n",
            "Processed 650/1563 batches...\n",
            "Processed 700/1563 batches...\n",
            "Processed 750/1563 batches...\n",
            "Processed 800/1563 batches...\n",
            "Processed 850/1563 batches...\n",
            "Processed 900/1563 batches...\n",
            "Processed 950/1563 batches...\n",
            "Processed 1000/1563 batches...\n",
            "Processed 1050/1563 batches...\n",
            "Processed 1100/1563 batches...\n",
            "Processed 1150/1563 batches...\n",
            "Processed 1200/1563 batches...\n",
            "Processed 1250/1563 batches...\n",
            "Processed 1300/1563 batches...\n",
            "Processed 1350/1563 batches...\n",
            "Processed 1400/1563 batches...\n",
            "Processed 1450/1563 batches...\n",
            "Processed 1500/1563 batches...\n",
            "Processed 1550/1563 batches...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample['predicted_sentiment'] = df_sample['predicted_sentiment'].replace('neutral', 'positive')"
      ],
      "metadata": {
        "id": "uzS2hyiMtP_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: Evaluation\n",
        "accuracy = accuracy_score(df_sample['sentiment_label'], df_sample['predicted_sentiment'])\n",
        "print(f\"\\n✅ Model Accuracy: {accuracy:.4f}\\n\")\n",
        "print(\"🔍 Classification Report:\")\n",
        "print(classification_report(df_sample['sentiment_label'], df_sample['predicted_sentiment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEuNYNJAj3Pt",
        "outputId": "c815aec6-5f53-4542-95a1-5e61af9c2346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model Accuracy: 0.9422\n",
            "\n",
            "🔍 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.86      0.87     23191\n",
            "    positive       0.96      0.97      0.96     76809\n",
            "\n",
            "    accuracy                           0.94    100000\n",
            "   macro avg       0.92      0.91      0.92    100000\n",
            "weighted avg       0.94      0.94      0.94    100000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}